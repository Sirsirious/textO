{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy, copy\n",
    "from queue import *\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "\n",
    "lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "\n",
    "nodes = pd.read_csv('data/Networks/MilkO/nodes.csv')\n",
    "edges = pd.read_csv('data/Networks/MilkO/edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gostaria', 'de', 'saber', 'qual', 'ser', 'o', 'alternativo', 'de', 'aproveitamento', 'de', 'bezerro', 'macho', 'oriundo', 'de', 'raça', 'leiteiro', '?']\n"
     ]
    }
   ],
   "source": [
    "mystr = nlp(u\"Gostaria de saber quais são as alternativas de aproveitamento de bezerros machos oriundos de raças leiteiras?\")\n",
    "\n",
    "print([token.lemma_ for token in mystr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = set()\n",
    "for index, node in nodes.iterrows():\n",
    "    dictionary.add(node['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {}\n",
    "for index, edge in edges.iterrows():\n",
    "    graph[edge['main']]={'weight':0, 'documents':[], 'edges':[]}\n",
    "    for i in range(1, len(edges.columns)):\n",
    "        if(isinstance(edge[i], float)):\n",
    "            break;\n",
    "        else:\n",
    "            graph[edge['main']]['edges'].append({'term':edge[i],'weight':0})\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSent(textEntry, graph):\n",
    "    tokenized = [lemmatizer(token.orth_, token.pos_)[0] for token in nlp(textEntry) if not (token.is_stop or token.is_punct or not token.is_alpha)]\n",
    "    traversedList = set()\n",
    "    i = 1\n",
    "    for word in tokenized:\n",
    "        if word in dictionary:\n",
    "            graph[word]['weight']=1\n",
    "            graph, traversedList = spread(word, graph, traversedList, previousScore=1)\n",
    "            i=i+1\n",
    "    return graph\n",
    "\n",
    "def spread(word, graph, traversedList, previousScore=1, weight=1, decay=0.5,treshold=0.1):\n",
    "    if graph[word]['weight']==0:\n",
    "        graph[word]['weight']=previousScore\n",
    "    futureTraversals = Queue()\n",
    "    if (previousScore > treshold):\n",
    "        for i in range(1, len(graph[word]['edges'])-1):\n",
    "            if graph[word]['edges'][i].get('weight')==0:\n",
    "                graph[word]['edges'][i].update({'weight':previousScore})\n",
    "            graph[word]['edges'][i].update({'weight':graph[word]['edges'][i].get('weight')*decay})\n",
    "            if graph[word]['edges'][i]['term'] not in traversedList:\n",
    "                futureTraversals.put({'term':graph[word]['edges'][i].get('term'), 'weight':graph[word]['edges'][i].get('weight')})\n",
    "                traversedList.add(graph[word]['edges'][i].get('term'))\n",
    "        if(not futureTraversals.empty()):\n",
    "            while not futureTraversals.empty():\n",
    "                totraverse = futureTraversals.get()\n",
    "                graph, traversedList = spread(word=totraverse['term'], graph=graph, traversedList=traversedList, previousScore=totraverse['weight'])\n",
    "\n",
    "    else:\n",
    "        return graph, traversedList\n",
    "    return graph, traversedList\n",
    "\n",
    "def activeGraph(graph):\n",
    "    gcopy = copy.deepcopy(graph)\n",
    "    itemsToPop = []\n",
    "    for val in gcopy:\n",
    "        if gcopy[val]['weight']==0:\n",
    "            itemsToPop.append(val)\n",
    "        else:\n",
    "            for edge in gcopy[val]['edges']:\n",
    "                if edge['weight'] ==0:\n",
    "                    gcopy[val]['edges'].remove(edge)\n",
    "    for item in itemsToPop:\n",
    "        gcopy.pop(item, None)\n",
    "    return gcopy\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leite': {'weight': 1, 'documents': [], 'edges': []}}\n"
     ]
    }
   ],
   "source": [
    "#%%pixie_debugger\n",
    "g2 = copy.deepcopy(graph)\n",
    "g2 = processSent(\"\"\"\n",
    "Sou veterinária e trabalho na area de qualidade de leite na regiao de Passos-MG. Gostaria de saber se alguem tem algum dado cientifico que fale sobre a eficacia do uso de hipoclorito de sodio como produto para pre e pos dipping.\n",
    "\n",
    "\"\"\", g2)\n",
    "print(activeGraph(g2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAFDCAYAAAB/UdRdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAABQNJREFUeJzt1TEBwCAQwMBS/54fFYSBOwXZsmZmPgDguP92AAC8wnQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASBiugAQMV0AiJguAERMFwAipgsAEdMFgIjpAkDEdAEgYroAEDFdAIiYLgBETBcAIqYLABHTBYCI6QJAxHQBIGK6ABAxXQCImC4AREwXACKmCwAR0wWAiOkCQMR0ASCyAR3iBoLgmtTtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "def toNetworkx(graph):\n",
    "    G = nx.Graph()\n",
    "    for node in graph:\n",
    "        for edge in graph[node]['edges']:\n",
    "            if edge['weight']!=0:\n",
    "                G.add_edge(node, edge['term'])\n",
    "    return G\n",
    "G = toNetworkx(activeGraph(g2))\n",
    "nx.draw(G, with_labels=True)\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
