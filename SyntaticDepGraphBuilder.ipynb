{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "\n",
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(doenças, 'nmod', 'agentes'),\n",
       " (pelos, 'amod', 'bovinos'),\n",
       " (carrapatos, 'amod', 'bovinos')}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(r'Quais agentes de doenças podem ser transmitidos aos bovinos pelos carrapatos?')\n",
    "#[token for token in doc if (token.pos_ == 'NOUN' or token.pos_ =='VERB')]\n",
    "#displacy.render(doc, style='dep', jupyter=True)\n",
    "set([(token, token.dep_, token.head.text) for token in doc if (token.pos_ in ['VERB', \"NOUN\", \"ADJ\", 'ADV'] and token.dep_ in ['obj', 'nmod', 'amod', 'compound'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('data/Raw/quinhentas_perguntas.csv', sep=',', header=0)\n",
    "answers = pd.read_csv('data/Raw/quinhentas_respostas.csv', sep=\",\", header=0)\n",
    "corpus['resposta'] = answers['resposta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = set()\n",
    "lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "for i, row in corpus.iterrows():\n",
    "    text = row['pergunta']+\" \"+row['resposta']\n",
    "    doc = nlp(text)\n",
    "    #relations.update((lemmatizer(token.orth_, token.pos_)[0], token.dep_, lemmatizer(token.head.text, token.head.pos_)[0]) for token in doc if (token.pos_ in ['VERB', \"NOUN\", \"ADJ\", 'ADV'] and token.dep_ in ['obj', 'nsubj', 'iobj', 'obl', 'amod', 'compound', 'conj', 'flat']))\n",
    "    for token in doc:\n",
    "        tLemma = lemmatizer(token.orth_, token.pos_)[0]\n",
    "        if not tLemma in topterms:\n",
    "            continue\n",
    "        descendants = (w for w in token.children if w.pos_ in [\"VERB\", \"NOUN\", \"ADJ\"])\n",
    "        for children in descendants:\n",
    "            cLemma = lemmatizer(children.orth_, children.pos_)[0]\n",
    "            if not cLemma in topterms:\n",
    "                continue\n",
    "            if children.dep_ in ['obj', 'nsubj', 'iobj']:\n",
    "                relations.add((tLemma, children.dep_, cLemma))\n",
    "                continue\n",
    "            if children.dep_ == 'conj' and children.pos_==token.pos_=='NOUN':\n",
    "                relations.add((tLemma, children.dep_, cLemma))\n",
    "                continue\n",
    "            if token.pos_ == \"NOUN\" and children.pos_ == \"NOUN\" and children.dep_ in ['flat', 'compound']:\n",
    "                relations.add((tLemma, children.dep_, cLemma))\n",
    "                continue\n",
    "            if token.pos_ == \"NOUN\" and children.pos_ == \"ADJ\" and children.dep_ == \"amod\":\n",
    "                relations.add((tLemma, children.dep_, cLemma))\n",
    "                continue\n",
    "            if token.pos_ == \"NOUN\" and children.pos_ == \"VERB\" and children.dep_ == \"obl\":\n",
    "                relations.add((tLemma, children.dep_, cLemma))\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('benefício', 'compound', 'heterose'),\n",
       " ('início', 'compound', 'manhã'),\n",
       " ('mercado', 'compound', 'produto')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in relations if w[1]==\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src/\")\n",
    "from CorpusProcessingTools.terms import TermExtractor\n",
    "#df = corpus\n",
    "#df[df.columns[1]] = df[df.columns[1]] + df[df.columns[2]]\n",
    "topterms = TermExtractor.getTopTerms(df, 2600, 'pt', True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = set(topterms)\n",
    "terms = list(terms)\n",
    "tdf = pd.DataFrame(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.to_csv('data/TreatedTerms/tfidfterms.csv')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
